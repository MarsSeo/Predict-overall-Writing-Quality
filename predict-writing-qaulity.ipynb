{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de9409f3",
   "metadata": {
    "papermill": {
     "duration": 0.008875,
     "end_time": "2024-01-20T09:21:55.547123",
     "exception": false,
     "start_time": "2024-01-20T09:21:55.538248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c5ea0a3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-20T09:21:55.565626Z",
     "iopub.status.busy": "2024-01-20T09:21:55.564921Z",
     "iopub.status.idle": "2024-01-20T09:22:04.558403Z",
     "shell.execute_reply": "2024-01-20T09:22:04.557396Z"
    },
    "papermill": {
     "duration": 9.006227,
     "end_time": "2024-01-20T09:22:04.561242",
     "exception": false,
     "start_time": "2024-01-20T09:21:55.555015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from collections import Counter,defaultdict\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Deep Learning Tools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "seed=116\n",
    "import random\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "import warnings#\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf31b59",
   "metadata": {
    "papermill": {
     "duration": 0.007409,
     "end_time": "2024-01-20T09:22:04.577387",
     "exception": false,
     "start_time": "2024-01-20T09:22:04.569978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227fb1eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:22:04.596095Z",
     "iopub.status.busy": "2024-01-20T09:22:04.595260Z",
     "iopub.status.idle": "2024-01-20T09:22:04.600892Z",
     "shell.execute_reply": "2024-01-20T09:22:04.599698Z"
    },
    "papermill": {
     "duration": 0.017288,
     "end_time": "2024-01-20T09:22:04.602755",
     "exception": false,
     "start_time": "2024-01-20T09:22:04.585467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_folds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee0b65f",
   "metadata": {
    "papermill": {
     "duration": 0.007883,
     "end_time": "2024-01-20T09:22:04.618919",
     "exception": false,
     "start_time": "2024-01-20T09:22:04.611036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2. Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8669ab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:22:04.636563Z",
     "iopub.status.busy": "2024-01-20T09:22:04.635934Z",
     "iopub.status.idle": "2024-01-20T09:22:23.487148Z",
     "shell.execute_reply": "2024-01-20T09:22:23.485894Z"
    },
    "papermill": {
     "duration": 18.862589,
     "end_time": "2024-01-20T09:22:23.489341",
     "exception": false,
     "start_time": "2024-01-20T09:22:04.626752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_logs):8405898\n",
      "len(test_logs):6\n"
     ]
    }
   ],
   "source": [
    "train_logs=pd.read_csv(\"/kaggle/input/linking-writing-processes-to-writing-quality/train_logs.csv\")\n",
    "print(f\"len(train_logs):{len(train_logs)}\")\n",
    "train_logs=train_logs.sort_values(by=['id', 'down_time'])\n",
    "train_logs = train_logs.reset_index(drop=True)\n",
    "train_logs['event_id'] = train_logs.groupby('id').cumcount() + 1\n",
    "\n",
    "train_scores=pd.read_csv(\"/kaggle/input/linking-writing-processes-to-writing-quality/train_scores.csv\")\n",
    "\n",
    "test_logs=pd.read_csv(\"/kaggle/input/linking-writing-processes-to-writing-quality/test_logs.csv\")\n",
    "print(f\"len(test_logs):{len(test_logs)}\")\n",
    "test_logs=test_logs.sort_values(by=['id', 'down_time'])\n",
    "test_logs = test_logs.reset_index(drop=True)\n",
    "test_logs['event_id'] = test_logs.groupby('id').cumcount() + 1\n",
    "test_logs.to_csv(\"test_logs.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab984f4d",
   "metadata": {
    "papermill": {
     "duration": 0.007925,
     "end_time": "2024-01-20T09:22:23.505949",
     "exception": false,
     "start_time": "2024-01-20T09:22:23.498024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b43ab",
   "metadata": {
    "papermill": {
     "duration": 0.007667,
     "end_time": "2024-01-20T09:22:23.521462",
     "exception": false,
     "start_time": "2024-01-20T09:22:23.513795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.1. Preprocess(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d14eafc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:22:23.540438Z",
     "iopub.status.busy": "2024-01-20T09:22:23.540005Z",
     "iopub.status.idle": "2024-01-20T09:22:23.556158Z",
     "shell.execute_reply": "2024-01-20T09:22:23.554588Z"
    },
    "papermill": {
     "duration": 0.029944,
     "end_time": "2024-01-20T09:22:23.559486",
     "exception": false,
     "start_time": "2024-01-20T09:22:23.529542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getEssays(df):\n",
    "    textInputDf = df[['id', 'activity', 'cursor_position', 'text_change']]\n",
    "    textInputDf = textInputDf[textInputDf.activity != 'Nonproduction']\n",
    "    valCountsArr = textInputDf['id'].value_counts(sort=False).values\n",
    "    lastIndex = 0\n",
    "    essaySeries = pd.Series()\n",
    "    for index, valCount in enumerate(valCountsArr):\n",
    "        currTextInput = textInputDf[['activity', 'cursor_position', 'text_change']].iloc[lastIndex : lastIndex + valCount]\n",
    "        lastIndex += valCount\n",
    "        essayText = \"\"\n",
    "        for Input in currTextInput.values:\n",
    "            if Input[0] == 'Replace':\n",
    "                replaceTxt = Input[2].split(' => ')\n",
    "                essayText = essayText[:Input[1] - len(replaceTxt[1])] + replaceTxt[1] +essayText[Input[1] - len(replaceTxt[1]) + len(replaceTxt[0]):]\n",
    "                continue\n",
    "            if Input[0] == 'Paste':\n",
    "                essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "                continue\n",
    "            if Input[0] == 'Remove/Cut':\n",
    "                essayText = essayText[:Input[1]] + essayText[Input[1] + len(Input[2]):]\n",
    "                continue\n",
    "            if \"M\" in Input[0]:\n",
    "                croppedTxt = Input[0][10:]\n",
    "                splitTxt = croppedTxt.split(' To ')\n",
    "                valueArr = [item.split(', ') for item in splitTxt]\n",
    "                moveData = (int(valueArr[0][0][1:]), \n",
    "                            int(valueArr[0][1][:-1]), \n",
    "                            int(valueArr[1][0][1:]), \n",
    "                            int(valueArr[1][1][:-1]))\n",
    "                if moveData[0] != moveData[2]:\n",
    "                    if moveData[0] < moveData[2]:\n",
    "                        essayText = essayText[:moveData[0]] + essayText[moveData[1]:moveData[3]] +\\\n",
    "                        essayText[moveData[0]:moveData[1]] + essayText[moveData[3]:]\n",
    "                    else:\n",
    "                        essayText = essayText[:moveData[2]] + essayText[moveData[0]:moveData[1]] +\\\n",
    "                        essayText[moveData[2]:moveData[0]] + essayText[moveData[1]:]\n",
    "                continue\n",
    "            essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "        essaySeries[index] = essayText\n",
    "    essaySeries.index =  textInputDf['id'].unique()\n",
    "    return pd.DataFrame(essaySeries, columns=['essay']).reset_index().rename(columns={\"index\":'id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3bc7e5",
   "metadata": {
    "papermill": {
     "duration": 0.007679,
     "end_time": "2024-01-20T09:22:23.575739",
     "exception": false,
     "start_time": "2024-01-20T09:22:23.568060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2. Preprocess (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea99132b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:22:23.594050Z",
     "iopub.status.busy": "2024-01-20T09:22:23.593645Z",
     "iopub.status.idle": "2024-01-20T09:22:23.613914Z",
     "shell.execute_reply": "2024-01-20T09:22:23.612431Z"
    },
    "papermill": {
     "duration": 0.032722,
     "end_time": "2024-01-20T09:22:23.616432",
     "exception": false,
     "start_time": "2024-01-20T09:22:23.583710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q1(x):\n",
    "    return x.quantile(0.25)\n",
    "def q3(x):\n",
    "    return x.quantile(0.75)\n",
    "AGGREGATIONS = ['count', 'mean', 'std', 'min', 'max', 'first', 'last', 'sem', q1, 'median', q3, 'skew', kurtosis, 'sum']\n",
    "\n",
    "def split_essays_into_words(df):\n",
    "    essay_df = df\n",
    "    essay_df['word'] = essay_df['essay'].apply(lambda x: re.split(' |\\\\n|\\\\.|\\\\?|\\\\!',x))\n",
    "    essay_df = essay_df.explode('word')\n",
    "    essay_df['word_len'] = essay_df['word'].apply(lambda x: len(x))\n",
    "    essay_df = essay_df[essay_df['word_len'] != 0]\n",
    "    return essay_df\n",
    "\n",
    "def compute_word_aggregations(word_df):\n",
    "    word_agg_df = word_df[['id','word_len']].groupby(['id']).agg(AGGREGATIONS)\n",
    "    word_agg_df.columns = ['_'.join(x) for x in word_agg_df.columns]\n",
    "    word_agg_df['id'] = word_agg_df.index\n",
    "    for word_l in [5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "        word_agg_df[f'word_len_ge_{word_l}_count'] = word_df[word_df['word_len'] >= word_l].groupby(['id']).count().iloc[:, 0]\n",
    "        word_agg_df[f'word_len_ge_{word_l}_count'] = word_agg_df[f'word_len_ge_{word_l}_count'].fillna(0)\n",
    "    word_agg_df = word_agg_df.reset_index(drop=True)\n",
    "    return word_agg_df\n",
    "\n",
    "def split_essays_into_sentences(df):\n",
    "    essay_df = df\n",
    "    essay_df['sent'] = essay_df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!',x))\n",
    "    essay_df = essay_df.explode('sent')\n",
    "    essay_df['sent'] = essay_df['sent'].apply(lambda x: x.replace('\\n','').strip())\n",
    "    essay_df['sent_len'] = essay_df['sent'].apply(lambda x: len(x))\n",
    "    essay_df['sent_word_count'] = essay_df['sent'].apply(lambda x: len(x.split(' ')))\n",
    "    essay_df = essay_df[essay_df.sent_len!=0].reset_index(drop=True)\n",
    "    return essay_df\n",
    "\n",
    "def compute_sentence_aggregations(df):\n",
    "    sent_agg_df = pd.concat(\n",
    "        [df[['id','sent_len']].groupby(['id']).agg(AGGREGATIONS), df[['id','sent_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1\n",
    "    )\n",
    "    sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n",
    "    sent_agg_df['id'] = sent_agg_df.index\n",
    "\n",
    "    for sent_l in [50, 60, 75, 100]:\n",
    "        sent_agg_df[f'sent_len_ge_{sent_l}_count'] = df[df['sent_len'] >= sent_l].groupby(['id']).count().iloc[:, 0]\n",
    "        sent_agg_df[f'sent_len_ge_{sent_l}_count'] = sent_agg_df[f'sent_len_ge_{sent_l}_count'].fillna(0)\n",
    "    sent_agg_df = sent_agg_df.reset_index(drop=True)\n",
    "    sent_agg_df.drop(columns=[\"sent_word_count_count\"], inplace=True)\n",
    "    sent_agg_df = sent_agg_df.rename(columns={\"sent_len_count\":\"sent_count\"})\n",
    "    return sent_agg_df\n",
    "\n",
    "def split_essays_into_paragraphs(df):\n",
    "    essay_df = df\n",
    "    essay_df['paragraph'] = essay_df['essay'].apply(lambda x: x.split('\\n'))\n",
    "    essay_df = essay_df.explode('paragraph')\n",
    "    essay_df['paragraph_len'] = essay_df['paragraph'].apply(lambda x: len(x)) \n",
    "    essay_df['paragraph_word_count'] = essay_df['paragraph'].apply(lambda x: len(x.split(' ')))\n",
    "    essay_df = essay_df[essay_df.paragraph_len!=0].reset_index(drop=True)\n",
    "    return essay_df\n",
    "\n",
    "def compute_paragraph_aggregations(df):\n",
    "    paragraph_agg_df = pd.concat(\n",
    "        [df[['id','paragraph_len']].groupby(['id']).agg(AGGREGATIONS), df[['id','paragraph_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1\n",
    "    ) \n",
    "    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n",
    "    paragraph_agg_df['id'] = paragraph_agg_df.index\n",
    "    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n",
    "    paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n",
    "    paragraph_agg_df = paragraph_agg_df.rename(columns={\"paragraph_len_count\":\"paragraph_count\"})\n",
    "    return paragraph_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3a2d2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:22:23.637067Z",
     "iopub.status.busy": "2024-01-20T09:22:23.636550Z",
     "iopub.status.idle": "2024-01-20T09:22:44.692379Z",
     "shell.execute_reply": "2024-01-20T09:22:44.690326Z"
    },
    "papermill": {
     "duration": 21.069767,
     "end_time": "2024-01-20T09:22:44.695407",
     "exception": false,
     "start_time": "2024-01-20T09:22:23.625640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_essays\n",
      "train_word_agg_df\n",
      "train_sent_agg_df\n",
      "train_paragraph_agg_df\n",
      "test_essays\n",
      "test_word_agg_df\n",
      "test_sent_agg_df\n",
      "test_paragraph_agg_df\n"
     ]
    }
   ],
   "source": [
    "print(\"train_essays\")\n",
    "train_essays = pd.read_csv('/kaggle/input/writing-quality-challenge-constructed-essays/train_essays_fast.csv')\n",
    "print(\"train_word_agg_df\")\n",
    "train_word_agg_df = compute_word_aggregations(split_essays_into_words(train_essays))\n",
    "print(\"train_sent_agg_df\")\n",
    "train_sent_agg_df = compute_sentence_aggregations(split_essays_into_sentences(train_essays))\n",
    "print(\"train_paragraph_agg_df\")\n",
    "train_paragraph_agg_df = compute_paragraph_aggregations(split_essays_into_paragraphs(train_essays))\n",
    "print(\"test_essays\")\n",
    "test_essays = getEssays(test_logs)\n",
    "test_essays_copy=test_essays.copy()\n",
    "print(\"test_word_agg_df\")\n",
    "test_word_agg_df = compute_word_aggregations(split_essays_into_words(test_essays))\n",
    "print(\"test_sent_agg_df\")\n",
    "test_sent_agg_df = compute_sentence_aggregations(split_essays_into_sentences(test_essays))\n",
    "print(\"test_paragraph_agg_df\")\n",
    "test_paragraph_agg_df = compute_paragraph_aggregations(split_essays_into_paragraphs(test_essays))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1218ce",
   "metadata": {
    "papermill": {
     "duration": 0.008546,
     "end_time": "2024-01-20T09:22:44.712721",
     "exception": false,
     "start_time": "2024-01-20T09:22:44.704175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.3. Preprocess (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae16a8db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:22:44.732563Z",
     "iopub.status.busy": "2024-01-20T09:22:44.732126Z",
     "iopub.status.idle": "2024-01-20T09:27:04.897547Z",
     "shell.execute_reply": "2024-01-20T09:27:04.896066Z"
    },
    "papermill": {
     "duration": 260.178212,
     "end_time": "2024-01-20T09:27:04.899749",
     "exception": false,
     "start_time": "2024-01-20T09:22:44.721537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features for training data\n",
      "Starting to engineer features\n",
      "Engineering time data\n",
      "-> for gap 1\n",
      "-> for gap 2\n",
      "-> for gap 3\n",
      "-> for gap 5\n",
      "-> for gap 10\n",
      "-> for gap 20\n",
      "-> for gap 50\n",
      "-> for gap 100\n",
      "Engineering cursor position data\n",
      "-> for gap 1\n",
      "-> for gap 2\n",
      "-> for gap 3\n",
      "-> for gap 5\n",
      "-> for gap 10\n",
      "-> for gap 20\n",
      "-> for gap 50\n",
      "-> for gap 100\n",
      "Engineering word count data\n",
      "-> for gap 1\n",
      "-> for gap 2\n",
      "-> for gap 3\n",
      "-> for gap 5\n",
      "-> for gap 10\n",
      "-> for gap 20\n",
      "-> for gap 50\n",
      "-> for gap 100\n",
      "Engineering statistical summaries for features\n",
      "Engineering activity counts data\n",
      "Engineering event counts data\n",
      "Engineering text change counts data\n",
      "Engineering punctuation counts data\n",
      "Engineering input words data\n",
      "Engineering ratios data\n",
      "Done!\n",
      "-------------------------\n",
      "Engineering features for test data\n",
      "Starting to engineer features\n",
      "Engineering time data\n",
      "-> for gap 1\n",
      "-> for gap 2\n",
      "-> for gap 3\n",
      "-> for gap 5\n",
      "-> for gap 10\n",
      "-> for gap 20\n",
      "-> for gap 50\n",
      "-> for gap 100\n",
      "Engineering cursor position data\n",
      "-> for gap 1\n",
      "-> for gap 2\n",
      "-> for gap 3\n",
      "-> for gap 5\n",
      "-> for gap 10\n",
      "-> for gap 20\n",
      "-> for gap 50\n",
      "-> for gap 100\n",
      "Engineering word count data\n",
      "-> for gap 1\n",
      "-> for gap 2\n",
      "-> for gap 3\n",
      "-> for gap 5\n",
      "-> for gap 10\n",
      "-> for gap 20\n",
      "-> for gap 50\n",
      "-> for gap 100\n",
      "Engineering statistical summaries for features\n",
      "Engineering activity counts data\n",
      "Engineering event counts data\n",
      "Engineering text change counts data\n",
      "Engineering punctuation counts data\n",
      "Engineering input words data\n",
      "Engineering ratios data\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "class Preprocessor:#数据预处理的一个类\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.activities = ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste','Move From']\n",
    "        self.events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft', '.', ',', \n",
    "              'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n",
    "        self.text_changes = ['q', ' ', 'NoChange', '.', ',', '\\n', \"'\", '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n",
    "        self.punctuations = ['\"', '.', ',', \"'\", '-', ';', ':', '?', '!', '<', '>', '/',\n",
    "                        '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+']\n",
    "        self.gaps = [1, 2, 3, 5, 10, 20, 50, 100]\n",
    "        \n",
    "        self.idf = defaultdict(float)\n",
    "    \n",
    "    def activity_counts(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'activity': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tmp_df['activity'].values:\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.activities:\n",
    "                di[k] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'activity_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "\n",
    "        cnts = ret.sum(1)\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = np.log(df.shape[0] / (ret[col].sum() + 1))\n",
    "                self.idf[col] = idf\n",
    "            ret[col] = 1 + np.log(ret[col] / cnts)\n",
    "            ret[col] *= idf\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def event_counts(self, df, colname):\n",
    "        tmp_df = df.groupby('id').agg({colname: list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tmp_df[colname].values:\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.events:\n",
    "                di[k] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'{colname}_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "\n",
    "        cnts = ret.sum(1)\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = df.shape[0] / (ret[col].sum() + 1)\n",
    "                idf = np.log(idf)\n",
    "                self.idf[col] = idf\n",
    "            \n",
    "            ret[col] = 1 + np.log(ret[col] / cnts)\n",
    "            ret[col] *= idf\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def text_change_counts(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'text_change': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tmp_df['text_change'].values:\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.text_changes:\n",
    "                di[k] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'text_change_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "\n",
    "        cnts = ret.sum(1)\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = df.shape[0] / (ret[col].sum() + 1)\n",
    "                idf = np.log(idf)\n",
    "                self.idf[col] = idf\n",
    "            \n",
    "            ret[col] = 1 + np.log(ret[col] / cnts)\n",
    "            ret[col] *= idf\n",
    "            \n",
    "        return ret\n",
    "    \n",
    "    def match_punctuations(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'down_event': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tmp_df['down_event'].values:\n",
    "            cnt = 0\n",
    "            items = list(Counter(li).items())\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in self.punctuations:\n",
    "                    cnt += v\n",
    "            ret.append(cnt)\n",
    "        ret = pd.DataFrame({'punct_cnt': ret})\n",
    "        return ret\n",
    "\n",
    "\n",
    "    def get_input_words(self, df):\n",
    "        tmp_df = df[(~df['text_change'].str.contains('=>'))&(df['text_change'] != 'NoChange')].reset_index(drop=True)\n",
    "        tmp_df = tmp_df.groupby('id').agg({'text_change': list}).reset_index()\n",
    "        tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: ''.join(x))\n",
    "        tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: re.findall(r'q+', x))\n",
    "        tmp_df['input_word_count'] = tmp_df['text_change'].apply(len)\n",
    "        tmp_df['input_word_length_mean'] = tmp_df['text_change'].apply(lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['input_word_length_max'] = tmp_df['text_change'].apply(lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['input_word_length_std'] = tmp_df['text_change'].apply(lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df.drop(['text_change'], axis=1, inplace=True)\n",
    "        return tmp_df\n",
    "    \n",
    "    def make_feats(self, df):\n",
    "        print(\"Starting to engineer features\")\n",
    "        feats = pd.DataFrame({'id': df['id'].unique().tolist()})\n",
    "        print(\"Engineering time data\")\n",
    "        for gap in self.gaps:\n",
    "            print(f\"-> for gap {gap}\")\n",
    "            df[f'up_time_shift{gap}'] = df.groupby('id')['up_time'].shift(gap)\n",
    "            df[f'action_time_gap{gap}'] = df['down_time'] - df[f'up_time_shift{gap}']\n",
    "        df.drop(columns=[f'up_time_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "\n",
    "        print(\"Engineering cursor position data\")\n",
    "        for gap in self.gaps:\n",
    "            print(f\"-> for gap {gap}\")\n",
    "            df[f'cursor_position_shift{gap}'] = df.groupby('id')['cursor_position'].shift(gap)\n",
    "            df[f'cursor_position_change{gap}'] = df['cursor_position'] - df[f'cursor_position_shift{gap}']\n",
    "            df[f'cursor_position_abs_change{gap}'] = np.abs(df[f'cursor_position_change{gap}'])\n",
    "        df.drop(columns=[f'cursor_position_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "\n",
    "        print(\"Engineering word count data\")\n",
    "        for gap in self.gaps:\n",
    "            print(f\"-> for gap {gap}\")\n",
    "            df[f'word_count_shift{gap}'] = df.groupby('id')['word_count'].shift(gap)\n",
    "            df[f'word_count_change{gap}'] = df['word_count'] - df[f'word_count_shift{gap}']\n",
    "            df[f'word_count_abs_change{gap}'] = np.abs(df[f'word_count_change{gap}'])\n",
    "        df.drop(columns=[f'word_count_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "        \n",
    "        print(\"Engineering statistical summaries for features\")\n",
    "        feats_stat = [\n",
    "            ('event_id', ['max']),\n",
    "            ('down_time',['mean', 'std', 'min', 'max', 'last', 'first', 'sem', 'median', 'sum']),\n",
    "            ('up_time',['mean', 'std', 'min', 'max', 'last', 'first', 'sem', 'median', 'sum']),\n",
    "            ('action_time', ['max', 'min', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt,'last', 'first','median']),\n",
    "            ('activity', ['nunique']),\n",
    "            ('down_event', ['nunique']),\n",
    "            ('up_event', ['nunique']),\n",
    "            ('text_change', ['nunique']),\n",
    "            ('cursor_position', ['nunique', 'max', 'quantile', 'sem', 'mean', 'std', 'min','last', 'first',  'median', 'sum']),\n",
    "            ('word_count', ['nunique', 'max', 'quantile', 'sem', 'mean', 'std', 'min', 'last', 'first','median', 'sum'])]\n",
    "        for gap in self.gaps:\n",
    "            feats_stat.extend([\n",
    "                (f'action_time_gap{gap}', ['max', 'min', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt]),\n",
    "                (f'cursor_position_change{gap}', ['max', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt]),\n",
    "                (f'word_count_change{gap}', ['max', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt])\n",
    "            ])\n",
    "        \n",
    "        pbar = feats_stat\n",
    "        for item in pbar:\n",
    "            colname, methods = item[0], item[1]\n",
    "            for method in methods:\n",
    "                if isinstance(method, str):\n",
    "                    method_name = method\n",
    "                else:\n",
    "                    method_name = method.__name__\n",
    "                tmp_df = df.groupby(['id']).agg({colname: method}).reset_index().rename(columns={colname: f'{colname}_{method_name}'})\n",
    "                feats = feats.merge(tmp_df, on='id', how='left')\n",
    "\n",
    "        print(\"Engineering activity counts data\")\n",
    "        tmp_df = self.activity_counts(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "        print(\"Engineering event counts data\")\n",
    "        tmp_df = self.event_counts(df, 'down_event')\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "        tmp_df = self.event_counts(df, 'up_event')\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "        \n",
    "        print(\"Engineering text change counts data\")\n",
    "        tmp_df = self.text_change_counts(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "        \n",
    "        print(\"Engineering punctuation counts data\")\n",
    "        tmp_df = self.match_punctuations(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "        print(\"Engineering input words data\")\n",
    "        tmp_df = self.get_input_words(df)\n",
    "        feats = pd.merge(feats, tmp_df, on='id', how='left')\n",
    "\n",
    "        print(\"Engineering ratios data\")\n",
    "        feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n",
    "        feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n",
    "        feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n",
    "        feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n",
    "        print(\"Done!\")\n",
    "        return feats\n",
    "\n",
    "preprocessor = Preprocessor()\n",
    "print(\"Engineering features for training data\")\n",
    "\n",
    "train_feats = preprocessor.make_feats(train_logs)\n",
    "print(\"-\"*25)\n",
    "print(\"Engineering features for test data\")\n",
    "test_feats = preprocessor.make_feats(test_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41960faa",
   "metadata": {
    "papermill": {
     "duration": 0.010186,
     "end_time": "2024-01-20T09:27:04.921265",
     "exception": false,
     "start_time": "2024-01-20T09:27:04.911079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.4. Preprocess (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91194d42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:27:04.944660Z",
     "iopub.status.busy": "2024-01-20T09:27:04.944259Z",
     "iopub.status.idle": "2024-01-20T09:27:13.279130Z",
     "shell.execute_reply": "2024-01-20T09:27:13.277884Z"
    },
    "papermill": {
     "duration": 8.349945,
     "end_time": "2024-01-20T09:27:13.281663",
     "exception": false,
     "start_time": "2024-01-20T09:27:04.931718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for logs in [train_logs, test_logs]:\n",
    "    logs['up_time_lagged'] = logs.groupby('id')['up_time'].shift(1).fillna(logs['down_time'])\n",
    "    logs['time_diff'] = abs(logs['down_time'] - logs['up_time_lagged']) / 1000\n",
    "\n",
    "    group = logs.groupby('id')['time_diff']\n",
    "    largest_lantency = group.max()\n",
    "    smallest_lantency = group.min()\n",
    "    median_lantency = group.median()\n",
    "    initial_pause = logs.groupby('id')['down_time'].first() / 1000\n",
    "    pauses_half_sec = group.apply(lambda x: ((x > 0.5) & (x <= 1)).sum())\n",
    "    pauses_1_sec = group.apply(lambda x: ((x > 1) & (x <= 1.5)).sum())\n",
    "    pauses_1_half_sec = group.apply(lambda x: ((x > 1.5) & (x <= 2)).sum())\n",
    "    pauses_2_sec = group.apply(lambda x: ((x > 2) & (x <= 3)).sum())\n",
    "    pauses_3_sec = group.apply(lambda x: (x > 3).sum())\n",
    "\n",
    "    data.append(pd.DataFrame({\n",
    "        'id': logs['id'].unique(),\n",
    "        'largest_lantency': largest_lantency,\n",
    "        'smallest_lantency': smallest_lantency,\n",
    "        'median_lantency': median_lantency,\n",
    "        'initial_pause': initial_pause,\n",
    "        'pauses_half_sec': pauses_half_sec,\n",
    "        'pauses_1_sec': pauses_1_sec,\n",
    "        'pauses_1_half_sec': pauses_1_half_sec,\n",
    "        'pauses_2_sec': pauses_2_sec,\n",
    "        'pauses_3_sec': pauses_3_sec,\n",
    "    }).reset_index(drop=True))\n",
    "\n",
    "train_eD592674, test_eD592674 = data\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "train_feats = train_feats.merge(train_eD592674, on='id', how='left')\n",
    "test_feats = test_feats.merge(test_eD592674, on='id', how='left')\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc333f4",
   "metadata": {
    "papermill": {
     "duration": 0.010446,
     "end_time": "2024-01-20T09:27:13.303045",
     "exception": false,
     "start_time": "2024-01-20T09:27:13.292599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.5. Preprocess Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56610c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:27:13.325792Z",
     "iopub.status.busy": "2024-01-20T09:27:13.325424Z",
     "iopub.status.idle": "2024-01-20T09:27:13.364356Z",
     "shell.execute_reply": "2024-01-20T09:27:13.363144Z"
    },
    "papermill": {
     "duration": 0.053178,
     "end_time": "2024-01-20T09:27:13.367149",
     "exception": false,
     "start_time": "2024-01-20T09:27:13.313971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_feats=train_feats.merge(train_word_agg_df,on='id', how='left')\n",
    "train_feats=train_feats.merge(train_sent_agg_df,on='id', how='left')\n",
    "train_feats=train_feats.merge(train_paragraph_agg_df,on='id', how='left')\n",
    "\n",
    "test_feats=test_feats.merge(test_word_agg_df,on='id', how='left')\n",
    "test_feats=test_feats.merge(test_sent_agg_df,on='id', how='left')\n",
    "test_feats=test_feats.merge(test_paragraph_agg_df,on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3748ecf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:27:13.391039Z",
     "iopub.status.busy": "2024-01-20T09:27:13.389915Z",
     "iopub.status.idle": "2024-01-20T09:27:13.398204Z",
     "shell.execute_reply": "2024-01-20T09:27:13.396907Z"
    },
    "papermill": {
     "duration": 0.022832,
     "end_time": "2024-01-20T09:27:13.400868",
     "exception": false,
     "start_time": "2024-01-20T09:27:13.378036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns only in train set: {'score'}\n",
      "Columns only in test set: set()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming train_set and test_set are your dataframes\n",
    "train_columns = set(train_feats.columns)\n",
    "test_columns = set(test_feats.columns)\n",
    "\n",
    "# Columns present in train set but not in test set\n",
    "columns_only_in_train = train_columns - test_columns\n",
    "\n",
    "# Columns present in test set but not in train set\n",
    "columns_only_in_test = test_columns - train_columns\n",
    "\n",
    "print(\"Columns only in train set:\", columns_only_in_train)\n",
    "print(\"Columns only in test set:\", columns_only_in_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf48512",
   "metadata": {
    "papermill": {
     "duration": 0.010487,
     "end_time": "2024-01-20T09:27:13.422005",
     "exception": false,
     "start_time": "2024-01-20T09:27:13.411518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Train Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c787502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:27:13.445407Z",
     "iopub.status.busy": "2024-01-20T09:27:13.445047Z",
     "iopub.status.idle": "2024-01-20T09:27:13.753726Z",
     "shell.execute_reply": "2024-01-20T09:27:13.752687Z"
    },
    "papermill": {
     "duration": 0.323429,
     "end_time": "2024-01-20T09:27:13.756005",
     "exception": false,
     "start_time": "2024-01-20T09:27:13.432576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X columns: (400,)\n",
      "test_X columns: (400,)\n"
     ]
    }
   ],
   "source": [
    "train_X = train_feats.drop(['id','score'],axis=1)\n",
    "train_y = train_feats['score']\n",
    "\n",
    "train_X.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "train_y.replace([np.inf, -np.inf], 0, inplace = True)\n",
    "\n",
    "columns_to_drop = train_X.columns[train_X.isnull().sum() > 10]\n",
    "\n",
    "train_X.drop(columns_to_drop, axis=1, inplace=True)\n",
    "train_X.fillna(train_X.mean(), inplace=True)\n",
    "\n",
    "test_X = test_feats.drop('id',axis=1)\n",
    "\n",
    "test_X.replace([np.inf, -np.inf], 0, inplace = True)\n",
    "test_X.drop(columns_to_drop, axis=1, inplace=True)\n",
    "test_X.fillna(test_X.mean(), inplace=True)\n",
    "\n",
    "X_features = train_X.columns.tolist()\n",
    "\n",
    "# should be size of (395, ) \n",
    "print(f'train_X columns: {train_X.columns.shape}')\n",
    "print(f'test_X columns: {test_X.columns.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3527c35",
   "metadata": {
    "papermill": {
     "duration": 0.095201,
     "end_time": "2024-01-20T09:27:13.863161",
     "exception": false,
     "start_time": "2024-01-20T09:27:13.767960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d3112",
   "metadata": {
    "papermill": {
     "duration": 0.010752,
     "end_time": "2024-01-20T09:27:13.885551",
     "exception": false,
     "start_time": "2024-01-20T09:27:13.874799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.1. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7caeb7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:27:13.910314Z",
     "iopub.status.busy": "2024-01-20T09:27:13.908775Z",
     "iopub.status.idle": "2024-01-20T09:27:13.920658Z",
     "shell.execute_reply": "2024-01-20T09:27:13.919569Z"
    },
    "papermill": {
     "duration": 0.026703,
     "end_time": "2024-01-20T09:27:13.922977",
     "exception": false,
     "start_time": "2024-01-20T09:27:13.896274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "\n",
    "\n",
    "    lgb_params_1 = {'reg_alpha': 0.007678095440286993, \n",
    "                    'reg_lambda': 0.34230534302168353, \n",
    "                    'colsample_bytree': 0.627061253588415, \n",
    "                    'subsample': 0.854942238828458, \n",
    "                    'learning_rate': 0.038697981947473245, \n",
    "                    'num_leaves': 22, \n",
    "                    'max_depth': 37, \n",
    "                    'min_child_samples': 18,\n",
    "                    'random_state': seed,\n",
    "                    'n_estimators': 150,\n",
    "                    \"objective\": \"regression\",\n",
    "                    \"metric\": \"rmse\",\n",
    "                    'force_col_wise': True,\n",
    "                    \"verbosity\": 0,}\n",
    "\n",
    "    lgb_params_2 =  {'boosting_type': 'gbdt', \n",
    "                     'metric': 'rmse',\n",
    "                     'random_state': seed,\n",
    "                     'reg_alpha': 0.003188447814669599, \n",
    "                     'reg_lambda': 0.0010228604507564066, \n",
    "                     'colsample_bytree': 0.5420247656839267, \n",
    "                     'subsample': 0.9778252382803456, \n",
    "                     'feature_fraction': 0.8,\n",
    "                     'bagging_freq': 1,\n",
    "                     'bagging_fraction': 0.75,\n",
    "                     'learning_rate': 0.01716485155812008, \n",
    "                     'num_leaves': 19, \n",
    "                     'min_child_samples': 46,\n",
    "                     'verbosity': -1,\n",
    "                     'random_state': 42,\n",
    "                     'n_estimators': 500,\n",
    "                     'device_type': 'cpu'}\n",
    "\n",
    "    catboost_params = {\"iterations\": 1000,\n",
    "                       \"learning_rate\": 0.1,\n",
    "                       \"depth\": 6,\n",
    "                       \"eval_metric\": 'RMSE',\n",
    "                       \"random_seed\": seed,  # Ensure 'seed' is defined somewhere in your code\n",
    "                       \"bagging_temperature\": 0.2,\n",
    "                       \"od_type\": 'Iter',\n",
    "                       \"metric_period\": 50,\n",
    "                       \"od_wait\": 20,\n",
    "                       \"verbose\": False}\n",
    "\n",
    "    xgb_params={'reg_alpha': 0.0008774661176012108,\n",
    "                'reg_lambda': 2.542812743920178,\n",
    "                'colsample_bynode': 0.7839026197349153,\n",
    "                'subsample': 0.8994226268096415, \n",
    "                'eta': 0.04730766698056879, \n",
    "                'max_depth': 3, \n",
    "                'n_estimators': 1024,\n",
    "                'random_state': 42,\n",
    "                'eval_metric': 'rmse'}\n",
    "\n",
    "    # 5 models\n",
    "    lgb_model_1 = LGBMRegressor(**lgb_params_1)\n",
    "    lgb_model_2 = LGBMRegressor(**lgb_params_2)\n",
    "    cb_model = CatBoostRegressor(**catboost_params)\n",
    "    xgb_model = XGBRegressor(**xgb_params)\n",
    "    svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "\n",
    "    models = []\n",
    "    models.append((lgb_model_1, 'lgbm_1'))\n",
    "    models.append((lgb_model_2, 'lgbm_2'))\n",
    "    models.append((cb_model, 'catboost'))\n",
    "    models.append((xgb_model, 'xgboost'))\n",
    "    models.append((svr_model, 'svr'))\n",
    "    # models.append((svr_model, 'svr'))\n",
    "#     print(models)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67c5e2c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:27:13.948154Z",
     "iopub.status.busy": "2024-01-20T09:27:13.947090Z",
     "iopub.status.idle": "2024-01-20T09:27:13.954148Z",
     "shell.execute_reply": "2024-01-20T09:27:13.952316Z"
    },
    "papermill": {
     "duration": 0.022921,
     "end_time": "2024-01-20T09:27:13.957038",
     "exception": false,
     "start_time": "2024-01-20T09:27:13.934117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = pd.DataFrame(make_model())[0][1]\n",
    "# model.fit(train_X, train_y)\n",
    "# prediction = model.predict(test_X)\n",
    "# clipped_predictions = np.clip(prediction, 0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30bdfd5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:27:13.981742Z",
     "iopub.status.busy": "2024-01-20T09:27:13.980610Z",
     "iopub.status.idle": "2024-01-20T09:27:13.986702Z",
     "shell.execute_reply": "2024-01-20T09:27:13.984909Z"
    },
    "papermill": {
     "duration": 0.020963,
     "end_time": "2024-01-20T09:27:13.989595",
     "exception": false,
     "start_time": "2024-01-20T09:27:13.968632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_ids = test_feats['id'].values\n",
    "# submission = pd.DataFrame({'id': test_ids, 'score': clipped_predictions})\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9b7234",
   "metadata": {
    "papermill": {
     "duration": 0.01081,
     "end_time": "2024-01-20T09:27:14.012342",
     "exception": false,
     "start_time": "2024-01-20T09:27:14.001532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.2. First Training & Inference (to get Feature Importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebfa57d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:27:14.036981Z",
     "iopub.status.busy": "2024-01-20T09:27:14.036307Z",
     "iopub.status.idle": "2024-01-20T09:38:00.276351Z",
     "shell.execute_reply": "2024-01-20T09:38:00.274271Z"
    },
    "papermill": {
     "duration": 646.256772,
     "end_time": "2024-01-20T09:38:00.280181",
     "exception": false,
     "start_time": "2024-01-20T09:27:14.023409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---lgbm_1---\n",
      "--- | Fold # 1 | ---\n",
      "Fold #1, RMSE: 0.6199676481116945\n",
      "--- | Fold # 2 | ---\n",
      "Fold #2, RMSE: 0.5616024284068566\n",
      "--- | Fold # 3 | ---\n",
      "Fold #3, RMSE: 0.6555362603354432\n",
      "--- | Fold # 4 | ---\n",
      "Fold #4, RMSE: 0.6508981346607098\n",
      "--- | Fold # 5 | ---\n",
      "Fold #5, RMSE: 0.613181560711195\n",
      "--- | Fold # 6 | ---\n",
      "Fold #6, RMSE: 0.5980724109799842\n",
      "--- | Fold # 7 | ---\n",
      "Fold #7, RMSE: 0.5863035851841022\n",
      "--- | Fold # 8 | ---\n",
      "Fold #8, RMSE: 0.6797684763204279\n",
      "--- | Fold # 9 | ---\n",
      "Fold #9, RMSE: 0.5968646737783446\n",
      "--- | Fold # 10 | ---\n",
      "Fold #10, RMSE: 0.6348282383490511\n",
      "Average RMSE for lgbm_1: 0.6197023416837808\n",
      "---lgbm_2---\n",
      "--- | Fold # 1 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #1, RMSE: 0.6237130093066905\n",
      "--- | Fold # 2 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #2, RMSE: 0.566245254738372\n",
      "--- | Fold # 3 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #3, RMSE: 0.6488900539991386\n",
      "--- | Fold # 4 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #4, RMSE: 0.6479376114499283\n",
      "--- | Fold # 5 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #5, RMSE: 0.5968239589971027\n",
      "--- | Fold # 6 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #6, RMSE: 0.6029094966773192\n",
      "--- | Fold # 7 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #7, RMSE: 0.5872862283830669\n",
      "--- | Fold # 8 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #8, RMSE: 0.6666763729073034\n",
      "--- | Fold # 9 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #9, RMSE: 0.6056369171244881\n",
      "--- | Fold # 10 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #10, RMSE: 0.6261997906532689\n",
      "Average RMSE for lgbm_2: 0.6172318694236678\n",
      "---catboost---\n",
      "--- | Fold # 1 | ---\n",
      "Fold #1, RMSE: 0.644667239064148\n",
      "--- | Fold # 2 | ---\n",
      "Fold #2, RMSE: 0.5826606456931854\n",
      "--- | Fold # 3 | ---\n",
      "Fold #3, RMSE: 0.6673706019036013\n",
      "--- | Fold # 4 | ---\n",
      "Fold #4, RMSE: 0.6770539101875376\n",
      "--- | Fold # 5 | ---\n",
      "Fold #5, RMSE: 0.6168214044870405\n",
      "--- | Fold # 6 | ---\n",
      "Fold #6, RMSE: 0.6187424342640971\n",
      "--- | Fold # 7 | ---\n",
      "Fold #7, RMSE: 0.5985203340710671\n",
      "--- | Fold # 8 | ---\n",
      "Fold #8, RMSE: 0.6764834514261848\n",
      "--- | Fold # 9 | ---\n",
      "Fold #9, RMSE: 0.6175876666368987\n",
      "--- | Fold # 10 | ---\n",
      "Fold #10, RMSE: 0.6407389984186472\n",
      "Average RMSE for catboost: 0.6340646686152408\n",
      "---xgboost---\n",
      "--- | Fold # 1 | ---\n",
      "Fold #1, RMSE: 0.6407458396800463\n",
      "--- | Fold # 2 | ---\n",
      "Fold #2, RMSE: 0.5706846823910059\n",
      "--- | Fold # 3 | ---\n",
      "Fold #3, RMSE: 0.6696635509650825\n",
      "--- | Fold # 4 | ---\n",
      "Fold #4, RMSE: 0.6597285698107314\n",
      "--- | Fold # 5 | ---\n",
      "Fold #5, RMSE: 0.6194790265128505\n",
      "--- | Fold # 6 | ---\n",
      "Fold #6, RMSE: 0.5938301234288482\n",
      "--- | Fold # 7 | ---\n",
      "Fold #7, RMSE: 0.5969628894851923\n",
      "--- | Fold # 8 | ---\n",
      "Fold #8, RMSE: 0.673743174689281\n",
      "--- | Fold # 9 | ---\n",
      "Fold #9, RMSE: 0.6063227139040533\n",
      "--- | Fold # 10 | ---\n",
      "Fold #10, RMSE: 0.6383415919779588\n",
      "Average RMSE for xgboost: 0.626950216284505\n",
      "---svr---\n",
      "--- | Fold # 1 | ---\n",
      "Fold #1, RMSE: 0.6717312388918297\n",
      "--- | Fold # 2 | ---\n",
      "Fold #2, RMSE: 0.6159342357478054\n",
      "--- | Fold # 3 | ---\n",
      "Fold #3, RMSE: 0.6777994509380432\n",
      "--- | Fold # 4 | ---\n",
      "Fold #4, RMSE: 0.6997979702002928\n",
      "--- | Fold # 5 | ---\n",
      "Fold #5, RMSE: 0.6334461190674805\n",
      "--- | Fold # 6 | ---\n",
      "Fold #6, RMSE: 0.6836758789859488\n",
      "--- | Fold # 7 | ---\n",
      "Fold #7, RMSE: 0.5915575633350634\n",
      "--- | Fold # 8 | ---\n",
      "Fold #8, RMSE: 0.7202135225343398\n",
      "--- | Fold # 9 | ---\n",
      "Fold #9, RMSE: 0.6392561695159809\n",
      "--- | Fold # 10 | ---\n",
      "Fold #10, RMSE: 0.6649834689965489\n",
      "Average RMSE for svr: 0.6598395618213333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Assuming num_folds, seed, train_X, and train_y are defined\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed + num_folds)\n",
    "models_and_errors_dict = {}\n",
    "\n",
    "# Initialize dictionaries for cumulative feature importances\n",
    "cumulative_importance = {model_type: {col: 0 for col in train_X.columns} for _, model_type in make_model()}\n",
    "\n",
    "for model, model_type in make_model():\n",
    "    print(f'---{model_type}---')\n",
    "    model_averaged_rmse = 0\n",
    "    oof_pred = np.zeros((len(train_X)))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(train_X), start=1):\n",
    "        print(f'--- | Fold # {fold} | ---')\n",
    "\n",
    "        X_train, X_val = train_X.iloc[train_index], train_X.iloc[val_index]\n",
    "        y_train, y_val = train_y.iloc[train_index], train_y.iloc[val_index]\n",
    "\n",
    "        # Scale data for models that need it\n",
    "        if model_type == 'svr':\n",
    "            imputer = SimpleImputer(strategy='mean')\n",
    "            X_train_imputed = imputer.fit_transform(X_train.copy())\n",
    "            X_val_imputed = imputer.transform(X_val.copy())\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "            X_val_scaled = scaler.transform(X_val_imputed)\n",
    "            \n",
    "            X_train = X_train_scaled\n",
    "            X_val = X_val_scaled\n",
    "            \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_val)\n",
    "        oof_pred[val_index] = predictions\n",
    "\n",
    "        # Calculate and store RMSE\n",
    "        rmse = RMSE(y_val, predictions)\n",
    "        model_averaged_rmse += rmse / num_folds  \n",
    "        print(f'Fold #{fold}, RMSE: {rmse}')\n",
    "\n",
    "        # Store results\n",
    "        if model_type not in models_and_errors_dict:\n",
    "            models_and_errors_dict[model_type] = []\n",
    "            if model_type == 'svr':\n",
    "                models_and_errors_dict[model_type].append((model, rmse, imputer, scaler,oof_pred))\n",
    "            else:\n",
    "                models_and_errors_dict[model_type].append((model, rmse, None, None, oof_pred))  \n",
    "\n",
    "        # Accumulate feature importances for tree-based models\n",
    "        if model_type in ['lgbm_1', 'lgbm_2', 'catboost', 'xgboost']:\n",
    "            feature_importance = model.feature_importances_\n",
    "            for i, col in enumerate(train_X.columns):\n",
    "                cumulative_importance[model_type][col] += feature_importance[i]\n",
    "\n",
    "    print(f'Average RMSE for {model_type}: {model_averaged_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057b4b14",
   "metadata": {
    "papermill": {
     "duration": 0.014668,
     "end_time": "2024-01-20T09:38:00.312150",
     "exception": false,
     "start_time": "2024-01-20T09:38:00.297482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.3. Rank Feature Importances & Get Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2125e43f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:38:00.345584Z",
     "iopub.status.busy": "2024-01-20T09:38:00.344439Z",
     "iopub.status.idle": "2024-01-20T09:38:00.361770Z",
     "shell.execute_reply": "2024-01-20T09:38:00.360776Z"
    },
    "papermill": {
     "duration": 0.03735,
     "end_time": "2024-01-20T09:38:00.364095",
     "exception": false,
     "start_time": "2024-01-20T09:38:00.326745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Top 350 Features across all models:\n",
      "{'input_word_count', 'cursor_position_change10_mean', 'up_event_8_count', 'action_time_gap50_quantile', 'text_change_5_count', 'word_count_change10_std', 'down_event_8_count', 'action_time_gap20_quantile', 'action_time_gap100_sum', 'word_count_last', 'action_time_gap10_std', 'cursor_position_change5_sum', 'cursor_position_change20_mean', 'action_time_gap100_kurt', 'word_len_ge_7_count', 'action_time_gap50_skew', 'up_event_7_count', 'cursor_position_change100_std', 'input_word_length_std', 'down_event_7_count', 'action_time_max', 'cursor_position_std', 'paragraph_count', 'action_time_gap1_kurt', 'cursor_position_change100_sum', 'action_time_gap2_skew', 'action_time_gap2_sem', 'word_count_change3_std', 'action_time_gap5_sum', 'text_change_nunique', 'up_event_nunique', 'action_time_gap50_std', 'down_event_6_count', 'action_time_gap1_mean', 'down_time_std', 'paragraph_word_count_last', 'cursor_position_change20_skew', 'text_change_9_count', 'cursor_position_change100_sem', 'activity_3_count', 'pauses_1_half_sec', 'sent_len_min', 'cursor_position_change3_skew', 'cursor_position_change50_max', 'cursor_position_change2_sem', 'action_time_skew', 'word_time_ratio', 'down_event_10_count', 'word_count_change20_sem', 'cursor_position_change3_sem', 'action_time_gap2_min', 'word_len_ge_5_count', 'action_time_gap100_quantile', 'cursor_position_change50_sum', 'cursor_position_change5_max', 'up_time_std', 'word_count_change5_sem', 'down_event_1_count', 'paragraph_len_q1', 'action_time_gap50_min', 'down_event_14_count', 'cursor_position_change2_mean', 'action_time_gap20_skew', 'median_lantency', 'word_event_ratio', 'up_event_13_count', 'paragraph_word_count_mean', 'action_time_mean', 'cursor_position_change100_skew', 'sent_len_skew', 'cursor_position_change1_max', 'down_event_5_count', 'cursor_position_change20_sum', 'activity_2_count', 'cursor_position_change100_kurt', 'word_count_std', 'paragraph_len_first', 'paragraph_len_q3', 'paragraph_len_min', 'action_time_gap50_kurt', 'action_time_gap20_mean', 'word_count_mean', 'word_count_change100_sem', 'cursor_position_change2_skew', 'word_len_sem', 'action_time_gap3_sum', 'cursor_position_change100_max', 'sent_len_ge_100_count', 'sent_word_count_first', 'word_count_change1_skew', 'sent_len_first', 'cursor_position_mean', 'sent_len_median', 'word_count_change3_skew', 'cursor_position_change10_sum', 'up_time_min', 'word_len_kurtosis', 'paragraph_word_count_q3', 'text_change_2_count', 'action_time_gap5_min', 'action_time_gap10_skew', 'word_count_change100_max', 'action_time_gap5_std', 'word_count_change100_skew', 'word_count_change10_skew', 'action_time_gap5_mean', 'text_change_7_count', 'sent_len_ge_50_count', 'input_word_length_max', 'cursor_position_quantile', 'action_time_gap50_mean', 'sent_len_max', 'text_change_12_count', 'down_event_13_count', 'cursor_position_change5_skew', 'cursor_position_change3_std', 'cursor_position_change2_max', 'up_time_sem', 'action_time_sum', 'action_time_gap10_max', 'text_change_8_count', 'cursor_position_change50_mean', 'action_time_kurt', 'action_time_gap3_skew', 'up_event_5_count', 'word_count_change20_std', 'sent_word_count_last', 'word_count_change50_std', 'action_time_gap1_min', 'idle_time_ratio', 'pauses_2_sec', 'cursor_position_change3_max', 'word_len_sum', 'word_count_sem', 'cursor_position_change1_skew', 'up_event_4_count', 'word_count_change100_std', 'cursor_position_change20_sem', 'word_len_first', 'sent_word_count_skew', 'word_len_ge_8_count', 'word_count_change50_sem', 'word_count_change20_skew', 'paragraph_word_count_sum', 'word_count_change2_std', 'up_event_2_count', 'cursor_position_change50_std', 'word_count_change50_skew', 'action_time_gap10_quantile', 'action_time_median', 'action_time_gap100_sem', 'action_time_gap100_mean', 'sent_len_q1', 'down_event_3_count', 'sent_word_count_mean', 'word_count_change5_skew', 'word_count_change5_std', 'cursor_position_change5_std', 'cursor_position_change10_skew', 'cursor_position_change10_sem', 'cursor_position_change50_sem', 'up_event_12_count', 'sent_word_count_max', 'action_time_gap20_sum', 'paragraph_word_count_q1', 'action_time_gap5_skew', 'cursor_position_change3_kurt', 'word_len_ge_12_count', 'action_time_gap50_max', 'word_count_change50_kurt', 'word_len_ge_6_count', 'cursor_position_max', 'down_time_min', 'action_time_sem', 'action_time_gap5_quantile', 'cursor_position_change2_std', 'paragraph_word_count_min', 'text_change_3_count', 'action_time_gap3_quantile', 'action_time_gap100_max', 'word_count_change5_kurt', 'action_time_gap10_sem', 'action_time_gap100_min', 'action_time_last', 'pauses_1_sec', 'word_len_last', 'sent_count', 'sent_word_count_std', 'paragraph_len_mean', 'down_event_nunique', 'up_time_mean', 'sent_len_std', 'word_count_change10_kurt', 'input_word_length_mean', 'action_time_gap5_max', 'cursor_position_change1_mean', 'text_change_1_count', 'sent_word_count_median', 'down_event_11_count', 'action_time_gap2_quantile', 'sent_len_ge_60_count', 'sent_word_count_min', 'action_time_gap3_min', 'cursor_position_change2_kurt', 'action_time_gap1_quantile', 'cursor_position_change5_mean', 'sent_len_ge_75_count', 'cursor_position_change20_kurt', 'cursor_position_last', 'word_len_ge_9_count', 'paragraph_len_max', 'word_len_ge_10_count', 'sent_len_sem', 'paragraph_len_sum', 'word_count_change1_std', 'word_len_skew', 'cursor_position_change50_quantile', 'action_time_gap20_kurt', 'cursor_position_change3_mean', 'sent_word_count_q1', 'text_change_11_count', 'word_count_quantile', 'paragraph_word_count_max', 'action_time_gap5_kurt', 'action_time_gap10_min', 'cursor_position_change100_mean', 'cursor_position_change5_kurt', 'sent_word_count_kurtosis', 'sent_len_kurtosis', 'sent_len_q3', 'word_count_change2_skew', 'text_change_6_count', 'word_len_std', 'action_time_gap10_kurt', 'action_time_gap2_kurt', 'action_time_gap1_std', 'paragraph_word_count_first', 'cursor_position_change20_std', 'cursor_position_change1_std', 'cursor_position_sum', 'up_event_1_count', 'sent_word_count_sem', 'action_time_first', 'word_count_change2_kurt', 'action_time_gap50_sem', 'text_change_0_count', 'cursor_position_change2_sum', 'text_change_10_count', 'word_count_change3_kurt', 'word_count_sum', 'word_count_change1_kurt', 'paragraph_word_count_median', 'cursor_position_nunique', 'action_time_gap1_sum', 'cursor_position_change5_sem', 'activity_1_count', 'up_event_11_count', 'action_time_gap3_kurt', 'up_event_6_count', 'action_time_gap20_std', 'word_count_change3_sem', 'sent_len_mean', 'sent_len_last', 'action_time_gap100_skew', 'down_time_sem', 'down_event_12_count', 'action_time_gap1_max', 'cursor_position_change100_quantile', 'word_count_nunique', 'pauses_half_sec', 'word_len_mean', 'paragraph_len_median', 'sent_len_sum', 'text_change_13_count', 'down_event_4_count', 'word_count_change100_sum', 'word_count_median', 'down_event_0_count', 'word_count_change100_mean', 'action_time_gap1_sem', 'action_time_std', 'down_time_first', 'word_count_change100_kurt', 'cursor_position_change1_kurt', 'sent_word_count_q3', 'cursor_position_median', 'word_count_change20_kurt', 'cursor_position_change10_max', 'activity_0_count', 'action_time_gap20_min', 'word_len_ge_11_count', 'action_time_gap1_skew', 'text_change_4_count', 'cursor_position_sem', 'up_event_0_count', 'word_count_change10_sem', 'cursor_position_change50_skew', 'up_event_3_count', 'action_time_quantile', 'cursor_position_change3_sum', 'up_time_max', 'pauses_3_sec', 'paragraph_len_last', 'word_count_change1_sem', 'action_time_gap3_max', 'word_len_count', 'punct_cnt', 'action_time_gap100_std', 'down_event_2_count', 'action_time_gap20_sem'}\n",
      "Common Features as List: 310\n"
     ]
    }
   ],
   "source": [
    "top_k = 350\n",
    "\n",
    "top_k_features_per_model = {}\n",
    "\n",
    "for model_type, importances in cumulative_importance.items():\n",
    "    if model_type not in ['svr']: \n",
    "        total_importance = sum(importances.values())\n",
    "        avg_importance = {col: (imp / num_folds) / total_importance for col, imp in importances.items()}\n",
    "\n",
    "        ranked_features = sorted(avg_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_k_features = [feature for feature, _ in ranked_features[:top_k]]\n",
    "\n",
    "        top_k_features_per_model[model_type] = top_k_features\n",
    "\n",
    "common_features = set(top_k_features_per_model[next(iter(top_k_features_per_model))])\n",
    "for features in top_k_features_per_model.values():\n",
    "    common_features.intersection_update(features)\n",
    "\n",
    "print(f\"Common Top {top_k} Features across all models:\")\n",
    "print(common_features)\n",
    "\n",
    "common_features_list = list(common_features)\n",
    "print(\"Common Features as List:\", len(common_features_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f766d0",
   "metadata": {
    "papermill": {
     "duration": 0.015174,
     "end_time": "2024-01-20T09:38:00.396873",
     "exception": false,
     "start_time": "2024-01-20T09:38:00.381699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.4. Use common Features to train & get oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8e3234e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:38:00.428930Z",
     "iopub.status.busy": "2024-01-20T09:38:00.427981Z",
     "iopub.status.idle": "2024-01-20T09:46:56.270533Z",
     "shell.execute_reply": "2024-01-20T09:46:56.269631Z"
    },
    "papermill": {
     "duration": 535.860304,
     "end_time": "2024-01-20T09:46:56.273344",
     "exception": false,
     "start_time": "2024-01-20T09:38:00.413040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---lgbm_1---\n",
      "--- | Fold # 1 | ---\n",
      "Fold #1, RMSE: 0.6265812635695837\n",
      "--- | Fold # 2 | ---\n",
      "Fold #2, RMSE: 0.5634821519635933\n",
      "--- | Fold # 3 | ---\n",
      "Fold #3, RMSE: 0.6552093163784364\n",
      "--- | Fold # 4 | ---\n",
      "Fold #4, RMSE: 0.643096753889907\n",
      "--- | Fold # 5 | ---\n",
      "Fold #5, RMSE: 0.6127125514743366\n",
      "--- | Fold # 6 | ---\n",
      "Fold #6, RMSE: 0.5925064747977018\n",
      "--- | Fold # 7 | ---\n",
      "Fold #7, RMSE: 0.5917254798334421\n",
      "--- | Fold # 8 | ---\n",
      "Fold #8, RMSE: 0.6736208430819208\n",
      "--- | Fold # 9 | ---\n",
      "Fold #9, RMSE: 0.5987980545194814\n",
      "--- | Fold # 10 | ---\n",
      "Fold #10, RMSE: 0.6229100529346661\n",
      "Average RMSE for lgbm_1: 0.6180642942443069\n",
      "---lgbm_2---\n",
      "--- | Fold # 1 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #1, RMSE: 0.6227447494796925\n",
      "--- | Fold # 2 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #2, RMSE: 0.5679092353440874\n",
      "--- | Fold # 3 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #3, RMSE: 0.6489429352500286\n",
      "--- | Fold # 4 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #4, RMSE: 0.6454351225293053\n",
      "--- | Fold # 5 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #5, RMSE: 0.5989294291440892\n",
      "--- | Fold # 6 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #6, RMSE: 0.6006847961918101\n",
      "--- | Fold # 7 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #7, RMSE: 0.5895527423412364\n",
      "--- | Fold # 8 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #8, RMSE: 0.6615163183258349\n",
      "--- | Fold # 9 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #9, RMSE: 0.616956191766863\n",
      "--- | Fold # 10 | ---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold #10, RMSE: 0.6235316457799174\n",
      "Average RMSE for lgbm_2: 0.6176203166152865\n",
      "---catboost---\n",
      "--- | Fold # 1 | ---\n",
      "Fold #1, RMSE: 0.6373032569912666\n",
      "--- | Fold # 2 | ---\n",
      "Fold #2, RMSE: 0.5694100055149344\n",
      "--- | Fold # 3 | ---\n",
      "Fold #3, RMSE: 0.6664235433020986\n",
      "--- | Fold # 4 | ---\n",
      "Fold #4, RMSE: 0.6581852981713324\n",
      "--- | Fold # 5 | ---\n",
      "Fold #5, RMSE: 0.6329386048759346\n",
      "--- | Fold # 6 | ---\n",
      "Fold #6, RMSE: 0.6104193004719299\n",
      "--- | Fold # 7 | ---\n",
      "Fold #7, RMSE: 0.5935259625113914\n",
      "--- | Fold # 8 | ---\n",
      "Fold #8, RMSE: 0.6805544783875008\n",
      "--- | Fold # 9 | ---\n",
      "Fold #9, RMSE: 0.5931933360055245\n",
      "--- | Fold # 10 | ---\n",
      "Fold #10, RMSE: 0.6319693420036947\n",
      "Average RMSE for catboost: 0.6273923128235607\n",
      "---xgboost---\n",
      "--- | Fold # 1 | ---\n",
      "Fold #1, RMSE: 0.6454528509659712\n",
      "--- | Fold # 2 | ---\n",
      "Fold #2, RMSE: 0.5701369433233815\n",
      "--- | Fold # 3 | ---\n",
      "Fold #3, RMSE: 0.6576987680592716\n",
      "--- | Fold # 4 | ---\n",
      "Fold #4, RMSE: 0.6595642843473332\n",
      "--- | Fold # 5 | ---\n",
      "Fold #5, RMSE: 0.6269125317246732\n",
      "--- | Fold # 6 | ---\n",
      "Fold #6, RMSE: 0.5993553487164835\n",
      "--- | Fold # 7 | ---\n",
      "Fold #7, RMSE: 0.5977300943382108\n",
      "--- | Fold # 8 | ---\n",
      "Fold #8, RMSE: 0.6791097266717979\n",
      "--- | Fold # 9 | ---\n",
      "Fold #9, RMSE: 0.609782194038024\n",
      "--- | Fold # 10 | ---\n",
      "Fold #10, RMSE: 0.644323650235397\n",
      "Average RMSE for xgboost: 0.6290066392420545\n",
      "---svr---\n",
      "--- | Fold # 1 | ---\n",
      "Fold #1, RMSE: 0.659406317694744\n",
      "--- | Fold # 2 | ---\n",
      "Fold #2, RMSE: 0.6132723037026989\n",
      "--- | Fold # 3 | ---\n",
      "Fold #3, RMSE: 0.6781345996938842\n",
      "--- | Fold # 4 | ---\n",
      "Fold #4, RMSE: 0.6950617092160876\n",
      "--- | Fold # 5 | ---\n",
      "Fold #5, RMSE: 0.6239368012382438\n",
      "--- | Fold # 6 | ---\n",
      "Fold #6, RMSE: 0.6767042948595348\n",
      "--- | Fold # 7 | ---\n",
      "Fold #7, RMSE: 0.5992949983076014\n",
      "--- | Fold # 8 | ---\n",
      "Fold #8, RMSE: 0.7111886380660686\n",
      "--- | Fold # 9 | ---\n",
      "Fold #9, RMSE: 0.6366674853485681\n",
      "--- | Fold # 10 | ---\n",
      "Fold #10, RMSE: 0.6583113301146578\n",
      "Average RMSE for svr: 0.6551978478242089\n"
     ]
    }
   ],
   "source": [
    "models_and_errors_dict = {}\n",
    "\n",
    "for model, model_type in make_model():\n",
    "    print(f'---{model_type}---')\n",
    "    model_averaged_rmse = 0\n",
    "    oof_pred = np.zeros((len(train_X)))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(train_X), start=1):\n",
    "        print(f'--- | Fold # {fold} | ---')\n",
    "\n",
    "        X_train, X_val = train_X[common_features_list].iloc[train_index], train_X[common_features_list].iloc[val_index]\n",
    "        y_train, y_val = train_y.iloc[train_index], train_y.iloc[val_index]\n",
    "\n",
    "        if model_type == 'svr':\n",
    "            imputer = SimpleImputer(strategy='mean')\n",
    "            X_train_imputed = imputer.fit_transform(X_train.copy())\n",
    "            X_val_imputed = imputer.transform(X_val.copy())\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "            X_val_scaled = scaler.transform(X_val_imputed)\n",
    "            \n",
    "            X_train = X_train_scaled\n",
    "            X_val = X_val_scaled\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        predictions = model.predict(X_val)\n",
    "        oof_pred[val_index] = predictions\n",
    "\n",
    "        rmse = RMSE(y_val, predictions)\n",
    "        model_averaged_rmse += rmse / num_folds  \n",
    "        print(f'Fold #{fold}, RMSE: {rmse}')\n",
    "\n",
    "        if model_type not in models_and_errors_dict:\n",
    "            models_and_errors_dict[model_type] = []\n",
    "            \n",
    "        if model_type == 'svr':\n",
    "            models_and_errors_dict[model_type].append((model, rmse, imputer, scaler, oof_pred))\n",
    "        else:\n",
    "            models_and_errors_dict[model_type].append((model, rmse, None, None, oof_pred))  \n",
    "    print(f'Average RMSE for {model_type}: {model_averaged_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0eb145",
   "metadata": {
    "papermill": {
     "duration": 0.017826,
     "end_time": "2024-01-20T09:46:56.309744",
     "exception": false,
     "start_time": "2024-01-20T09:46:56.291918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.5. Get Optimized Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb181244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:46:56.348795Z",
     "iopub.status.busy": "2024-01-20T09:46:56.348322Z",
     "iopub.status.idle": "2024-01-20T09:48:52.986820Z",
     "shell.execute_reply": "2024-01-20T09:48:52.985844Z"
    },
    "papermill": {
     "duration": 116.661735,
     "end_time": "2024-01-20T09:48:52.989732",
     "exception": false,
     "start_time": "2024-01-20T09:46:56.327997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current RMSE Score: 0.6147491465442274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b7e77745bf497fa70aa2e908e7fe25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_RMSE:0.6147491465442274, new_RMSE:0.6147490356275602\n",
      "current_RMSE:0.6147490356275602, new_RMSE:0.6147290807504068\n",
      "current_RMSE:0.6147290807504068, new_RMSE:0.614727658254777\n",
      "current_RMSE:0.614727658254777, new_RMSE:0.6147235696815408\n",
      "current_RMSE:0.6147235696815408, new_RMSE:0.6147077971609938\n",
      "current_RMSE:0.6147077971609938, new_RMSE:0.6146981690272634\n",
      "current_RMSE:0.6146981690272634, new_RMSE:0.6146928055572937\n",
      "current_RMSE:0.6146928055572937, new_RMSE:0.6146858966491054\n",
      "current_RMSE:0.6146858966491054, new_RMSE:0.6146714962581526\n",
      "current_RMSE:0.6146714962581526, new_RMSE:0.6146497708795445\n",
      "current_RMSE:0.6146497708795445, new_RMSE:0.6146463178312245\n",
      "current_RMSE:0.6146463178312245, new_RMSE:0.6146359337380163\n",
      "current_RMSE:0.6146359337380163, new_RMSE:0.614618390894158\n",
      "current_RMSE:0.614618390894158, new_RMSE:0.6146120269864865\n",
      "current_RMSE:0.6146120269864865, new_RMSE:0.6145986673863187\n",
      "current_RMSE:0.6145986673863187, new_RMSE:0.6145906014782694\n",
      "current_RMSE:0.6145906014782694, new_RMSE:0.6145846620917665\n",
      "current_RMSE:0.6145846620917665, new_RMSE:0.6145791780866816\n",
      "current_RMSE:0.6145791780866816, new_RMSE:0.614562497127939\n",
      "current_RMSE:0.614562497127939, new_RMSE:0.6145431838970019\n",
      "current_RMSE:0.6145431838970019, new_RMSE:0.6145411564568336\n",
      "current_RMSE:0.6145411564568336, new_RMSE:0.6145284923934191\n",
      "current_RMSE:0.6145284923934191, new_RMSE:0.6145133626006397\n",
      "current_RMSE:0.6145133626006397, new_RMSE:0.6145061456122278\n",
      "current_RMSE:0.6145061456122278, new_RMSE:0.6144951998997987\n",
      "current_RMSE:0.6144951998997987, new_RMSE:0.6144886968282731\n",
      "current_RMSE:0.6144886968282731, new_RMSE:0.6144821813831077\n",
      "current_RMSE:0.6144821813831077, new_RMSE:0.6144781228167727\n",
      "current_RMSE:0.6144781228167727, new_RMSE:0.614459160664366\n",
      "current_RMSE:0.614459160664366, new_RMSE:0.6144422605831971\n",
      "current_RMSE:0.6144422605831971, new_RMSE:0.6144416592480199\n",
      "current_RMSE:0.6144416592480199, new_RMSE:0.6144267145632515\n",
      "current_RMSE:0.6144267145632515, new_RMSE:0.6144139987732244\n",
      "current_RMSE:0.6144139987732244, new_RMSE:0.6144059284856331\n",
      "current_RMSE:0.6144059284856331, new_RMSE:0.6143973975621038\n",
      "current_RMSE:0.6143973975621038, new_RMSE:0.6143968036149455\n",
      "current_RMSE:0.6143968036149455, new_RMSE:0.6143924578950617\n",
      "current_RMSE:0.6143924578950617, new_RMSE:0.6143853662649946\n",
      "current_RMSE:0.6143853662649946, new_RMSE:0.6143827336339182\n",
      "current_RMSE:0.6143827336339182, new_RMSE:0.6143614897248394\n",
      "current_RMSE:0.6143614897248394, new_RMSE:0.6143470037293679\n",
      "current_RMSE:0.6143470037293679, new_RMSE:0.6143306030623833\n",
      "current_RMSE:0.6143306030623833, new_RMSE:0.614320302160526\n",
      "current_RMSE:0.614320302160526, new_RMSE:0.6143113783788533\n",
      "current_RMSE:0.6143113783788533, new_RMSE:0.6143052630790456\n",
      "current_RMSE:0.6143052630790456, new_RMSE:0.6143038167691368\n",
      "current_RMSE:0.6143038167691368, new_RMSE:0.6143018873414751\n",
      "current_RMSE:0.6143018873414751, new_RMSE:0.6142942194161833\n",
      "current_RMSE:0.6142942194161833, new_RMSE:0.6142930131776566\n",
      "current_RMSE:0.6142930131776566, new_RMSE:0.6142694870118717\n",
      "current_RMSE:0.6142694870118717, new_RMSE:0.6142574159717178\n",
      "current_RMSE:0.6142574159717178, new_RMSE:0.6142401605506833\n",
      "current_RMSE:0.6142401605506833, new_RMSE:0.61423227535602\n",
      "current_RMSE:0.61423227535602, new_RMSE:0.61422249790894\n",
      "current_RMSE:0.61422249790894, new_RMSE:0.6142187990012049\n",
      "current_RMSE:0.6142187990012049, new_RMSE:0.6142165000928695\n",
      "current_RMSE:0.6142165000928695, new_RMSE:0.6142087433601395\n",
      "current_RMSE:0.6142087433601395, new_RMSE:0.6141831550727108\n",
      "current_RMSE:0.6141831550727108, new_RMSE:0.6141734997910521\n",
      "current_RMSE:0.6141734997910521, new_RMSE:0.6141553895326526\n",
      "current_RMSE:0.6141553895326526, new_RMSE:0.6141499207976864\n",
      "current_RMSE:0.6141499207976864, new_RMSE:0.6141392895374848\n",
      "current_RMSE:0.6141392895374848, new_RMSE:0.6141380077235792\n",
      "current_RMSE:0.6141380077235792, new_RMSE:0.6141348560046694\n",
      "current_RMSE:0.6141348560046694, new_RMSE:0.6141289404646901\n",
      "current_RMSE:0.6141289404646901, new_RMSE:0.6141024962989878\n",
      "current_RMSE:0.6141024962989878, new_RMSE:0.6140952575124352\n",
      "current_RMSE:0.6140952575124352, new_RMSE:0.614076292357079\n",
      "current_RMSE:0.614076292357079, new_RMSE:0.6140732407676733\n",
      "current_RMSE:0.6140732407676733, new_RMSE:0.6140617555702785\n",
      "current_RMSE:0.6140617555702785, new_RMSE:0.614058886767186\n",
      "current_RMSE:0.614058886767186, new_RMSE:0.6140548129416964\n",
      "current_RMSE:0.6140548129416964, new_RMSE:0.6140275129263874\n",
      "current_RMSE:0.6140275129263874, new_RMSE:0.6140226913048706\n",
      "current_RMSE:0.6140226913048706, new_RMSE:0.6140028712167124\n",
      "current_RMSE:0.6140028712167124, new_RMSE:0.614002237391981\n",
      "current_RMSE:0.614002237391981, new_RMSE:0.6139898981569941\n",
      "current_RMSE:0.6139898981569941, new_RMSE:0.6139885944868786\n",
      "current_RMSE:0.6139885944868786, new_RMSE:0.6139863628467475\n",
      "current_RMSE:0.6139863628467475, new_RMSE:0.6139582070343376\n",
      "current_RMSE:0.6139582070343376, new_RMSE:0.6139558031809994\n",
      "current_RMSE:0.6139558031809994, new_RMSE:0.6139351281479616\n",
      "current_RMSE:0.6139351281479616, new_RMSE:0.6139237192908878\n",
      "current_RMSE:0.6139237192908878, new_RMSE:0.6139235920788769\n",
      "current_RMSE:0.6139235920788769, new_RMSE:0.6138945805457235\n",
      "current_RMSE:0.6138945805457235, new_RMSE:0.6138730650306126\n",
      "current_RMSE:0.6138730650306126, new_RMSE:0.6138632208085243\n",
      "current_RMSE:0.6138632208085243, new_RMSE:0.6138366352266199\n",
      "current_RMSE:0.6138366352266199, new_RMSE:0.6138166835875682\n",
      "current_RMSE:0.6138166835875682, new_RMSE:0.6138084043895219\n",
      "current_RMSE:0.6138084043895219, new_RMSE:0.6137843726860472\n",
      "current_RMSE:0.6137843726860472, new_RMSE:0.6137659853846094\n",
      "current_RMSE:0.6137659853846094, new_RMSE:0.6137592715563196\n",
      "current_RMSE:0.6137592715563196, new_RMSE:0.613737794375748\n",
      "current_RMSE:0.613737794375748, new_RMSE:0.6137209718301776\n",
      "current_RMSE:0.6137209718301776, new_RMSE:0.613715823673966\n",
      "current_RMSE:0.613715823673966, new_RMSE:0.6136969015899859\n",
      "current_RMSE:0.6136969015899859, new_RMSE:0.6136816441751798\n",
      "current_RMSE:0.6136816441751798, new_RMSE:0.6136780619499304\n",
      "current_RMSE:0.6136780619499304, new_RMSE:0.6136616954653656\n",
      "current_RMSE:0.6136616954653656, new_RMSE:0.613648003512815\n",
      "current_RMSE:0.613648003512815, new_RMSE:0.6136459874339341\n",
      "current_RMSE:0.6136459874339341, new_RMSE:0.6136321769806754\n",
      "current_RMSE:0.6136321769806754, new_RMSE:0.613620050778422\n",
      "current_RMSE:0.613620050778422, new_RMSE:0.6136196010178055\n",
      "current_RMSE:0.6136196010178055, new_RMSE:0.6136083469567507\n",
      "current_RMSE:0.6136083469567507, new_RMSE:0.6135977867493493\n",
      "current_RMSE:0.6135977867493493, new_RMSE:0.6135902060563603\n",
      "current_RMSE:0.6135902060563603, new_RMSE:0.6135812120448474\n",
      "current_RMSE:0.6135812120448474, new_RMSE:0.6135777547841144\n",
      "current_RMSE:0.6135777547841144, new_RMSE:0.6135703271259829\n",
      "current_RMSE:0.6135703271259829, new_RMSE:0.6135651322955735\n",
      "blending_weights: {'lgbm_1': 0.35, 'catboost': 0.15, 'xgboost': 0.0, 'svr': 0.16666666666666666, 'lgbm_2': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "lgb1_oof_pred = models_and_errors_dict['lgbm_1'][9][4]\n",
    "lgb2_oof_pred = models_and_errors_dict['lgbm_2'][9][4]\n",
    "cb_oof_pred = models_and_errors_dict['catboost'][9][4]\n",
    "xgb_oof_pred = models_and_errors_dict['xgboost'][9][4]\n",
    "svr_oof_pred = models_and_errors_dict['svr'][9][4]\n",
    "\n",
    "target = train_y.values\n",
    "\n",
    "current_RMSE = RMSE(target, (lgb1_oof_pred + lgb2_oof_pred + cb_oof_pred + xgb_oof_pred + svr_oof_pred) / 5)\n",
    "print(f'Current RMSE Score: {current_RMSE}')\n",
    "\n",
    "best_i, best_j, best_k, best_l = 0, 0, 0, 0\n",
    "margin = 300  \n",
    "step_size = 5 \n",
    "\n",
    "for i in tqdm(range(0, margin, step_size)):\n",
    "    for j in range(0, margin - i, step_size):\n",
    "        for k in range(0, margin - i - j, step_size):\n",
    "            for l in range(0, margin - i - j - k, step_size):\n",
    "                blend_oof_pred = (i * lgb1_oof_pred + j * cb_oof_pred + k * xgb_oof_pred + l * svr_oof_pred + (margin - i - j - k - l) * lgb2_oof_pred) / margin\n",
    "                new_RMSE = RMSE(target, blend_oof_pred)\n",
    "                if new_RMSE < current_RMSE:\n",
    "                    print(f\"current_RMSE:{current_RMSE}, new_RMSE:{new_RMSE}\")\n",
    "                    current_RMSE = new_RMSE\n",
    "                    best_i, best_j, best_k, best_l = i, j, k, l\n",
    "\n",
    "blending_weights = {\n",
    "    'lgbm_1': best_i / margin,\n",
    "    'catboost': best_j / margin,\n",
    "    'xgboost': best_k / margin,\n",
    "    'svr': best_l / margin,\n",
    "    'lgbm_2': (margin - best_i - best_j - best_k - best_l) / margin}\n",
    "\n",
    "print(f\"blending_weights: {blending_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c3622",
   "metadata": {
    "papermill": {
     "duration": 0.021869,
     "end_time": "2024-01-20T09:48:53.034548",
     "exception": false,
     "start_time": "2024-01-20T09:48:53.012679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Inference to Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3c5ebf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:48:53.080902Z",
     "iopub.status.busy": "2024-01-20T09:48:53.080353Z",
     "iopub.status.idle": "2024-01-20T09:48:53.627527Z",
     "shell.execute_reply": "2024-01-20T09:48:53.625792Z"
    },
    "papermill": {
     "duration": 0.573306,
     "end_time": "2024-01-20T09:48:53.629934",
     "exception": false,
     "start_time": "2024-01-20T09:48:53.056628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- lgbm_1 ---\n",
      "\n",
      "Using model 1 with error 0.6265812635695837\n",
      "(3, 310)\n",
      "Using model 2 with error 0.5634821519635933\n",
      "(3, 310)\n",
      "Using model 3 with error 0.6552093163784364\n",
      "(3, 310)\n",
      "Using model 4 with error 0.643096753889907\n",
      "(3, 310)\n",
      "Using model 5 with error 0.6127125514743366\n",
      "(3, 310)\n",
      "Using model 6 with error 0.5925064747977018\n",
      "(3, 310)\n",
      "Using model 7 with error 0.5917254798334421\n",
      "(3, 310)\n",
      "Using model 8 with error 0.6736208430819208\n",
      "(3, 310)\n",
      "Using model 9 with error 0.5987980545194814\n",
      "(3, 310)\n",
      "Using model 10 with error 0.6229100529346661\n",
      "(3, 310)\n",
      "Done.\n",
      "\n",
      "--- lgbm_2 ---\n",
      "\n",
      "Using model 1 with error 0.6227447494796925\n",
      "(3, 310)\n",
      "Using model 2 with error 0.5679092353440874\n",
      "(3, 310)\n",
      "Using model 3 with error 0.6489429352500286\n",
      "(3, 310)\n",
      "Using model 4 with error 0.6454351225293053\n",
      "(3, 310)\n",
      "Using model 5 with error 0.5989294291440892\n",
      "(3, 310)\n",
      "Using model 6 with error 0.6006847961918101\n",
      "(3, 310)\n",
      "Using model 7 with error 0.5895527423412364\n",
      "(3, 310)\n",
      "Using model 8 with error 0.6615163183258349\n",
      "(3, 310)\n",
      "Using model 9 with error 0.616956191766863\n",
      "(3, 310)\n",
      "Using model 10 with error 0.6235316457799174\n",
      "(3, 310)\n",
      "Done.\n",
      "\n",
      "--- catboost ---\n",
      "\n",
      "Using model 1 with error 0.6373032569912666\n",
      "(3, 310)\n",
      "Using model 2 with error 0.5694100055149344\n",
      "(3, 310)\n",
      "Using model 3 with error 0.6664235433020986\n",
      "(3, 310)\n",
      "Using model 4 with error 0.6581852981713324\n",
      "(3, 310)\n",
      "Using model 5 with error 0.6329386048759346\n",
      "(3, 310)\n",
      "Using model 6 with error 0.6104193004719299\n",
      "(3, 310)\n",
      "Using model 7 with error 0.5935259625113914\n",
      "(3, 310)\n",
      "Using model 8 with error 0.6805544783875008\n",
      "(3, 310)\n",
      "Using model 9 with error 0.5931933360055245\n",
      "(3, 310)\n",
      "Using model 10 with error 0.6319693420036947\n",
      "(3, 310)\n",
      "Done.\n",
      "\n",
      "--- xgboost ---\n",
      "\n",
      "Using model 1 with error 0.6454528509659712\n",
      "(3, 310)\n",
      "Using model 2 with error 0.5701369433233815\n",
      "(3, 310)\n",
      "Using model 3 with error 0.6576987680592716\n",
      "(3, 310)\n",
      "Using model 4 with error 0.6595642843473332\n",
      "(3, 310)\n",
      "Using model 5 with error 0.6269125317246732\n",
      "(3, 310)\n",
      "Using model 6 with error 0.5993553487164835\n",
      "(3, 310)\n",
      "Using model 7 with error 0.5977300943382108\n",
      "(3, 310)\n",
      "Using model 8 with error 0.6791097266717979\n",
      "(3, 310)\n",
      "Using model 9 with error 0.609782194038024\n",
      "(3, 310)\n",
      "Using model 10 with error 0.644323650235397\n",
      "(3, 310)\n",
      "Done.\n",
      "\n",
      "--- svr ---\n",
      "\n",
      "Using model 1 with error 0.659406317694744\n",
      "Using model 2 with error 0.6132723037026989\n",
      "Using model 3 with error 0.6781345996938842\n",
      "Using model 4 with error 0.6950617092160876\n",
      "Using model 5 with error 0.6239368012382438\n",
      "Using model 6 with error 0.6767042948595348\n",
      "Using model 7 with error 0.5992949983076014\n",
      "Using model 8 with error 0.7111886380660686\n",
      "Using model 9 with error 0.6366674853485681\n",
      "Using model 10 with error 0.6583113301146578\n",
      "Done.\n",
      "blending\n",
      "blended_score:0    1.848978\n",
      "1    1.802426\n",
      "2    1.845421\n",
      "Name: score_lgbm_1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_hats = dict()\n",
    "\n",
    "submission_df = pd.DataFrame(test_feats['id'])\n",
    "submission_df['score'] = 3.5\n",
    "\n",
    "X_unseen = test_X.copy()[common_features_list]\n",
    "X_unseen.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "for model_name, model_info in models_and_errors_dict.items():\n",
    "    print(f'\\n--- {model_name} ---\\n')\n",
    "    X_unseen_copy = X_unseen.copy()\n",
    "    y_hats[model_name] = []\n",
    "    \n",
    "    for ix, (trained_model, error, imputer, scaler,oof_pred) in enumerate(model_info, start=1):\n",
    "        print(f\"Using model {ix} with error {error}\")\n",
    "        if model_name == 'svr':\n",
    "            X_unseen_imputed = imputer.transform(X_unseen_copy)\n",
    "            X_unseen_scaled = scaler.transform(X_unseen_imputed)\n",
    "            y_hats[model_name].append(trained_model.predict(X_unseen_scaled))\n",
    "            \n",
    "        else:\n",
    "            print(X_unseen_copy.shape)\n",
    "            y_hats[model_name].append(trained_model.predict(X_unseen_copy))\n",
    "    if y_hats[model_name]:\n",
    "        y_hat_avg = np.mean(y_hats[model_name], axis=0)\n",
    "        submission_df['score_' + model_name] = y_hat_avg\n",
    "    print(\"Done.\")\n",
    "    \n",
    "print(\"blending\")\n",
    "blended_score=np.zeros((len(test_essays_copy)))\n",
    "for k, v in blending_weights.items():\n",
    "    blended_score += submission_df['score_' + k] * v\n",
    "print(f\"blended_score:{blended_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23955724",
   "metadata": {
    "papermill": {
     "duration": 0.020547,
     "end_time": "2024-01-20T09:48:53.671317",
     "exception": false,
     "start_time": "2024-01-20T09:48:53.650770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ff6a4fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T09:48:53.714356Z",
     "iopub.status.busy": "2024-01-20T09:48:53.713999Z",
     "iopub.status.idle": "2024-01-20T09:48:53.733698Z",
     "shell.execute_reply": "2024-01-20T09:48:53.732148Z"
    },
    "papermill": {
     "duration": 0.044449,
     "end_time": "2024-01-20T09:48:53.736456",
     "exception": false,
     "start_time": "2024-01-20T09:48:53.692007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>1.848978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2222bbbb</td>\n",
       "      <td>1.802426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4444cccc</td>\n",
       "      <td>1.845421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     score\n",
       "0  0000aaaa  1.848978\n",
       "1  2222bbbb  1.802426\n",
       "2  4444cccc  1.845421"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids = test_feats['id'].values\n",
    "blended_score = np.clip(blended_score, 0, 6)\n",
    "submission = pd.DataFrame({'id': test_ids, 'score': blended_score})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6678907,
     "sourceId": 59291,
     "sourceType": "competition"
    },
    {
     "datasetId": 3949123,
     "sourceId": 6973319,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1624.340203,
   "end_time": "2024-01-20T09:48:56.590021",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-20T09:21:52.249818",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2eec3d9a446b437681d952d1e82cf3f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "36f38c4c69b2498fb435dd026e87126b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4255dd7f93174121a8b05b66f127d813": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7821eab06d6042689ea9d57e0a1999bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f3854a3ecb8241749213b4fbb1732003",
       "max": 60.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2eec3d9a446b437681d952d1e82cf3f9",
       "value": 60.0
      }
     },
     "816ddbfbf66345d3832c90174175d9f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9dfbb8b6bdc04b329e38ecb14e9b5699": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_eb8137b3a20f4446ba6651442824ee38",
       "placeholder": "​",
       "style": "IPY_MODEL_36f38c4c69b2498fb435dd026e87126b",
       "value": "100%"
      }
     },
     "e5d38b426f794d509247502c3b06cbfb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb8137b3a20f4446ba6651442824ee38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f3854a3ecb8241749213b4fbb1732003": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9b7e77745bf497fa70aa2e908e7fe25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9dfbb8b6bdc04b329e38ecb14e9b5699",
        "IPY_MODEL_7821eab06d6042689ea9d57e0a1999bb",
        "IPY_MODEL_fbdf375699084163a1fa3b126c4d2504"
       ],
       "layout": "IPY_MODEL_816ddbfbf66345d3832c90174175d9f6"
      }
     },
     "fbdf375699084163a1fa3b126c4d2504": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e5d38b426f794d509247502c3b06cbfb",
       "placeholder": "​",
       "style": "IPY_MODEL_4255dd7f93174121a8b05b66f127d813",
       "value": " 60/60 [01:56&lt;00:00,  9.50it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
